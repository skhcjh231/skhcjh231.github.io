---
---

@string{CVPR = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>),}}
@string{ICCV = {{IEEE/CVF} Conference on International Conference on Computer Vision (<b>ICCV</b>),}}
@string{ECCV = {European Conference on Computer Vision (<b>ECCV</b>),}}
@string{IJCV = {International Journal of Computer Vision (<b>IJCV</b>),}}
@string{ICRA = {IEEE International Conference on Robotics and Automation (<b>ICRA</b>),}}
@string{arXiv = {arXiv preprint,}}


@inproceedings{song2024ontal,
  title={Online Temporal Action Localization with Memory-Augmented Transoformer},
  author={Youngkil Song* and Dongkeun Kim* and Minsu Cho and Suha Kwak},
  abstract={Online temporal action localization (On-TAL) is the task of identifying multiple action instances given a streaming video. Since existing methods take as input only a video segment of fixed size per iteration, they are limited in considering long-term context and require tuning the segment size carefully. To overcome these limitations, we propose memory-augmented transformer (MATR). MATR utilizes the memory queue that selectively preserves the past segment features, allowing to leverage long-term context for inference. We also propose a novel action localization method that observes the current input segment to predict the end time of the ongoing action and accesses the memory queue to estimate the start time of the action. Our method outperformed existing methods on two datasets, THUMOS14 and MUSES, surpassing not only TAL methods in the online setting but also some offline TAL methods.},
  booktitle=ECCV,
  year={2024},
  abbr={ECCV},
  equal_contrib={true},
  selected={true},
  code={https://github.com/skhcjh231/MATR_codebase},
  img_path={assets/img/publication_preview/ontal_teaser.png}
}

@inproceedings{kim2024cafe,
  title={Towards More Practical Group Activity Detection: A New Benchmark and Model},
  author={Dongkeun Kim and Youngkil Song and Minsu Cho and Suha Kwak},
  abstract={Group activity detection (GAD) is the task of identifying members of each group and classifying the activity of the group at the same time in a video. While GAD has been studied recently, there is still much room for improvement in both dataset and methodology due to their limited capability to address practical GAD scenarios. To resolve these issues, we first present a new dataset, dubbed Caf\'e. Unlike existing datasets, Caf\'e is constructed primarily for GAD and presents more practical scenarios and metrics, as well as being large-scale and providing rich annotations. Along with the dataset, we propose a new GAD model that deals with an unknown number of groups and latent group members efficiently and effectively. We evaluated our model on three datasets including Caf\'e, where it outperformed previous work in terms of both accuracy and inference speed.},
  booktitle=ECCV,
  year={2024},
  abbr={ECCV},
  selected={true},
  code={https://github.com/dk-kim/CAFE_codebase},
  website={https://dk-kim.github.io/CAFE/},
  img_path={assets/img/publication_preview/cafe_teaser.png}
}

